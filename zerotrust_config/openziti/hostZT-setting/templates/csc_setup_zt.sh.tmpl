#!/bin/bash

# Assumption
# Assuming the cluster is working along with traefik
# It is not normally necessary to obtain publicly trusted certificates for Ziti's TLS servers.
# Ziti manages the trust relationships between the controller and routers and clients independent of the web's root authorities.
# See the Alternative Web Server Certificates section for more information.

set -euo pipefail
source "$(dirname "$0")/common.sh"

setting_kubectl_helm(){

  master_floating_ip=$1
  ssh -i {{ ssh_private_key_path }} ubuntu@$master_floating_ip "sudo cat /etc/rancher/k3s/k3s.yaml" > ./k3s.yaml
  sed -i "s/127.0.0.1/${master_floating_ip}/" ./k3s.yaml
  }

setup_cert_ztctrl(){

  if ! kubectl get namespace "$CTRL_NAMESPACE" >/dev/null 2>&1; then
    echo "Creating namespace: $CTRL_NAMESPACE"
    kubectl create namespace "$CTRL_NAMESPACE"
  else
    echo "Namespace $CTRL_NAMESPACE already exists."
  fi

  log "setup_cert_ztctrl"
  helm repo add jetstack https://charts.jetstack.io

  log "cert-manager"
  helm upgrade --install cert-manager jetstack/cert-manager \
      --namespace cert-manager --create-namespace \
      --set crds.enabled=true

  wait_for_deployment cert-manager cert-manager


  log "trust-manager"
  helm upgrade --install trust-manager jetstack/trust-manager \
      --namespace cert-manager \
      --set crds.keep=false \
      --set app.trust.namespace=$CTRL_NAMESPACE

  wait_for_deployment cert-manager trust-manager

  log "zt-ctrl"
  helm repo add openziti https://docs.openziti.io/helm-charts/
  helm install ziti-controller openziti/ziti-controller \
    --namespace $CTRL_NAMESPACE \
    --set cert-manager.enabled=true \
    --set trust-manager.enabled=true \
    --set clientApi.advertisedHost="$CTRL_ADVERTISE" \
    --set clientApi.advertisedPort=443 \
    --set clientApi.service.type=ClusterIP \
    --set clientApi.traefikTcpRoute.enabled=true

    #--set clientApi.advertisedPort=32171 \
    #--set clientApi.service.type=NodePort \

# helm install ziti-controller openziti/ziti-controller \
#   --namespace $CTRL_NAMESPACE \
#   --set cert-manager.enabled=false \
#   --set trust-manager.enabled=false \
#   --set clientApi.advertisedHost="$CTRL_ADVERTISE" 

  wait_for_deployment "$CTRL_NAMESPACE" ziti-controller

  }

setup_dns(){
  # DNS setting 
  # env PUB_CTRL_IP="$PUB_CTRL_IP" envsubst < gke_dns_configmap.yml | kubectl apply -f -
  floating_ip="$1"
  hostnames="$2" #"ctrl.cloud.hong3nguyen.com router.cloud.hong3nguyen.com"

# Get the existing ConfigMap as JSON
  kubectl -n kube-system get configmap coredns -o json > coredns.json

# Update NodeHosts safely using jq
  jq --arg ip "$floating_ip" --arg hosts "$hostnames" \
    '.data.NodeHosts += "\n\($ip) \($hosts)"' coredns.json > coredns-patched.json

# Apply the patched ConfigMap
  kubectl -n kube-system apply -f coredns-patched.json

# Restart CoreDNS pods
  kubectl -n kube-system rollout restart deployment coredns

  wait_for_deployment kube-system coredns

  # CUSTOM_DNS_IP=$(kubectl get pod -n kube-system -l app=custom-dns-server -o jsonpath='{.items[0].status.podIP}')
  # kubectl patch configmap kube-dns -n kube-system --type merge -p "{\"data\":{\"stubDomains\":\"{\\\"{{ custom_domain }}\\\":[\\\"$CUSTOM_DNS_IP\\\"]}\"}}"
  # kubectl delete pods -n kube-system -l k8s-app=kube-dns
  # wait_for_deployment kube-system  custom-dns-server

}

# public router
setup_router_traefik(){
  router_id=$1
  advertised_address=$2
  namespace=$1-namespace

setup_router $router_id $namespace $advertised_address

kubectl patch pvc $router_id -n $namespace -p '{"spec":{"storageClassName":"local-path"}}'

# Check if pod is running
echo "Checking pod status..."

sleep 5
POD_STATUS=$(kubectl get pod -n $namespace -l app.kubernetes.io/name=ziti-router -o jsonpath="{.items[0].status.phase}" 2>/dev/null || echo "NotFound")

if [[ "$POD_STATUS" != "Running" ]]; then
  echo "Pod is not running (status: $POD_STATUS). Deleting pod and waiting..."
  kubectl delete pod -n $namespace -l app.kubernetes.io/name=ziti-router --ignore-not-found

  # Wait for the new pod to be recreated and become Running
  echo "Waiting for pod to become Running..."
  for i in {1..30}; do
    sleep 5
    POD_STATUS=$(kubectl get pod -n $namespace -l app.kubernetes.io/name=ziti-router -o jsonpath="{.items[0].status.phase}" 2>/dev/null || echo "NotFound")
    if [[ "$POD_STATUS" == "Running" ]]; then
      echo "Pod is now Running."
      break
    fi
  done

  if [[ "$POD_STATUS" != "Running" ]]; then
    echo "Pod did not reach Running state in time."
    exit 1
  fi
else
  echo "Pod is already Running."
fi

kubectl apply -f - <<EOF
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: $router_id-ingress
  namespace: $namespace
  annotations:
    kubernetes.io/ingress.class: traefik
spec:
  rules:
  - host: $advertised_address
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: $router_id-cloud
            port:
              number: 443
EOF
  }


sidecar_jaeger_gke(){
# This function sets up sidecars for  applications and exposes the central collector:
log "sidecar_jaeger_gke"
# setting sidecar
kubectl apply -f - <<EOF
apiVersion: opentelemetry.io/v1beta1
kind: OpenTelemetryCollector
metadata:
  name: sidecar-for-my-app
spec:
  mode: sidecar
  config:
    receivers:
      jaeger:
        protocols:
          thrift_compact: {}
    processors:
      batch:
        send_batch_size: 10000
        timeout: 5s

    exporters:
      debug: {}

    service:
      pipelines:
        traces:
          receivers: [jaeger]
          exporters: [debug]
EOF

# Setting for loadbalancer
# kubectl apply -f - <<EOF
# apiVersion: v1
# kind: Service
# metadata:
#   name: otel-collector
#   namespace: observability
# spec:
#   type: LoadBalancer
#   selector:
#     app: jaeger-inmemory-instance  # <- Ensure this label matches pod
#   ports:
#     - name: grpc
#       port: 4317
#       targetPort: 4317
#     - name: http
#       port: 4318
#       targetPort: 4318
# EOF

# Setting for traefik
kubectl apply -f - <<EOF
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: jaeger-ingress
  namespace: observability
  annotations:
    kubernetes.io/ingress.class: "traefik"
spec:
  rules:
    - host: {{ cloud.jaeger_advertised_address }}
      http:
        paths:
          - path: /
            pathType: Prefix
            backend:
              service:
                name: otel-collector
                port:
                  number: 4318  # HTTP port of OpenTelemetry Collector
EOF
  }


main(){
  # curl -sS https://get.openziti.io/install.bash | sudo bash -s openziti

  
  CTRL_ADVERTISE="{{ ziti_config.ctrl.cloud_ctrl.ctrl_advertised_address }}"
  ROUTER_ADVERTISE="{{ ziti_config.ctrl.cloud_ctrl.router.cloud_router_advertised_address }}"

  ROUTER_NAMESPACE="zt-router"
  CTRL_NAMESPACE="zt-ctrl"

  ROUTER_ID="ziti-{{ ziti_config.ctrl.cloud_ctrl.router.id | replace('_', '') }}"
  PUB_CTRL_IP="{{ cloud.cluster_ip }}"
  PUB_ROUTER_IP="{{ cloud.cluster_ip }}"
  PUB_JAEGER_IP="{{ cloud.cluster_ip }}"

  # setup cilium 
  setup_network

  # check ready from nodes 
  wait_for_nodes_ready

  setup_cert_ztctrl
  # wait_for_ip_and_advertise PUB_CTRL_IP CTRL_ADVERTISE \
  #   "kubectl get svc ziti-controller-client -n \"$CTRL_NAMESPACE\" -o jsonpath='{.status.loadBalancer.ingress[0].ip}'" \
  #   $CTRL_ADVERTISE
  
  CTRL_PASS=$(kubectl -n "$CTRL_NAMESPACE" get secrets ziti-controller-admin-secret -o go-template='{{"{{"}}index .data "admin-password" | base64decode {{"}}"}}')

  setup_localhost "$PUB_CTRL_IP" "$CTRL_ADVERTISE"

  setup_dns $PUB_CTRL_IP $CTRL_ADVERTISE

  login_zt "$CTRL_ADVERTISE" "$CTRL_PASS"

  setup_router_traefik "$ROUTER_ID" "$ROUTER_ADVERTISE"

  # wait_for_ip_and_advertise PUB_ROUTER_IP ROUTER_ADVERTISE \
  #   "kubectl get svc \"$ROUTER_ID-edge\" -n \"$ROUTER_NAMESPACE\" -o jsonpath='{.status.loadBalancer.ingress[0].ip}'" \
  #   $ROUTER_ADVERTISE

  setup_localhost "$PUB_ROUTER_IP" "$ROUTER_ADVERTISE"

  setup_dns $PUB_CTRL_IP $ROUTER_ADVERTISE

  log "Edge and Sensor deployment complete."

  log "setup jaeger"
  setup_jaeger

  log "setup sidecar"
  sidecar_jaeger_gke

  # wait_for_ip_and_advertise PUB_JAEGER_IP  \
  #   "kubectl get svc otel-collector -n observability -o jsonpath='{.status.loadBalancer.ingress[0].ip}'" \
  #   $ROUTER_ADVERTISE

}

main "$@"


